# üí∏ Financial Fraud Detection Model

This project focuses on building a robust **Financial Fraud Detection System** using various Machine Learning algorithms. The goal is to identify fraudulent financial transactions with high accuracy and reliability.

---

## üöÄ Overview

- Developed using **Logistic Regression**, **Decision Trees**, and **Multilayer Perceptron (MLP)**
- Achieved **98% average accuracy** across all models
- Worked with a **large dataset of 6.3 million transactions**
- Demonstrated strong capabilities in **data preprocessing**, **feature engineering**, and **model training**

---

## üß† Models Used

| Model                | Accuracy |
|---------------------|----------|
| Logistic Regression | 0.98     |
| Decision Tree       | 0.97     |
| MLP Classifier      | 0.99     |

---

## üìä Dataset

- The dataset contains **6.3 million+ transaction records**
- Features include transaction time, amount, location, device info, etc.
- Target variable indicates whether a transaction is **fraudulent (1)** or **genuine (0)**

> Note: Due to confidentiality or licensing restrictions, the dataset is not included in this repo. You can use a similar public dataset like [Kaggle's Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud).

---

## üîß Tech Stack

- Python (Pandas, NumPy, Scikit-learn)
- Jupyter Notebook / Google Colab
- Matplotlib, Seaborn (for visualization)

---

## üõ†Ô∏è Project Workflow

1. **Data Loading & Cleaning**  
   - Handled missing values, data types, and duplicates  
   - Analyzed data distribution and correlation

2. **Exploratory Data Analysis (EDA)**  
   - Visualized class imbalance and key feature distributions  
   - Detected outliers and patterns in fraudulent activity

3. **Feature Engineering**  
   - Normalized/Standardized numerical features  
   - Created new features based on domain logic

4. **Model Training**  
   - Trained Logistic Regression, Decision Tree, and MLP models  
   - Handled class imbalance using under/oversampling or class weights

5. **Evaluation**  
   - Evaluated using **accuracy**, **precision**, **recall**, **F1-score**, and **ROC-AUC**

---

## üìà Results

- **High accuracy (98%)** and strong performance across all models
- Able to detect fraudulent patterns with minimal false positives
- Scalable to large datasets

---

## üß† Key Learnings

- Working with large, imbalanced datasets
- Effective preprocessing techniques and pipeline design
- Understanding and comparing different ML models for classification tasks

---

